{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f28c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from imblearn.combine import SMOTETomek\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# 设置Matplotlib以支持中文字符和正确显示负号\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ===================== 1. 读取数据 =====================\n",
    "print(\"\\n[阶段1] 正在读取数据...\")\n",
    "# 建议使用相对路径或将路径存储在配置文件中，以提高代码的可移植性\n",
    "file_path = r'D:\\桌面\\2025年第四届“创新杯”（原钉钉杯）大学生大数据挑战赛初赛题目\\2025年第四届“创新杯”（原钉钉杯）大学生大数据挑战赛初赛题目\\A题\\data\\train_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ===================== 2. 预处理与特征工程 =====================\n",
    "print(\"\\n[阶段2] 正在进行预处理与特征工程...\")\n",
    "\n",
    "# --- 2.1 修正 Installation_Year 并创建 Machine_Age 特征 ---\n",
    "# 目的：处理原始数据中的异常年份（如未来年份），并将其转换为更有预测价值的“机龄”特征。\n",
    "print(\"  [2.1] 修正 Installation_Year 并创建 'Machine_Age' 特征...\")\n",
    "REFERENCE_YEAR = 2025  # 定义一个当前或未来的基准年份\n",
    "# 识别出无效年份（未来年份或过早的年份）\n",
    "invalid_years_mask = (df['Installation_Year'] > REFERENCE_YEAR) | (df['Installation_Year'] < 1980)\n",
    "# 如果存在无效年份，则进行修正\n",
    "if invalid_years_mask.any():\n",
    "    # 计算所有有效年份的中位数，用于填充，这比用均值更稳健，不易受极端值影响\n",
    "    valid_years_median = df.loc[~invalid_years_mask, 'Installation_Year'].median()\n",
    "    print(f\"    发现并修正 {invalid_years_mask.sum()} 个无效安装年份，使用中位数 {valid_years_median} 进行填充。\")\n",
    "    # 定位并替换无效年份\n",
    "    df.loc[invalid_years_mask, 'Installation_Year'] = valid_years_median\n",
    "# 计算机器年龄\n",
    "df['Machine_Age'] = REFERENCE_YEAR - df['Installation_Year']\n",
    "print(\"    'Machine_Age' 特征已创建。\")\n",
    "\n",
    "\n",
    "# --- 2.2 特征分箱: Last_Maintenance_Days_Ago ---\n",
    "# 目的：将连续的维护天数转换为离散的类别，帮助模型捕捉非线性关系。\n",
    "print(\"  [2.2] 对 'Last_Maintenance_Days_Ago' 进行特征分箱...\")\n",
    "# 定义分箱的边界，-1确保0也能被正确包含\n",
    "bins = [-1, 30, 90, np.inf]\n",
    "# 定义每个箱的标签\n",
    "labels = ['Maintenance_Recent', 'Maintenance_Medium', 'Maintenance_Long']\n",
    "# 使用pd.cut进行分箱操作\n",
    "df['Maintenance_Bin'] = pd.cut(df['Last_Maintenance_Days_Ago'], bins=bins, labels=labels)\n",
    "print(\"    'Maintenance_Bin' 特征已创建。\")\n",
    "\n",
    "\n",
    "# --- 2.3 创建交互特征 ---\n",
    "# 目的：组合现有特征，以发现可能存在的、单个特征无法表达的协同效应。\n",
    "print(\"  [2.3] 正在创建交互特征...\")\n",
    "# 功耗与温度的交互，可能反映机器在高负荷下的热状况\n",
    "df['Power_Temp_Interaction'] = df['Power_Consumption_kW'] * df['Temperature_C']\n",
    "# 振动与运行小时数的交互，可能反映累积的机械磨损\n",
    "df['Vibration_Hours_Interaction'] = df['Vibration_mms'] * df['Operational_Hours']\n",
    "# 维护频率，通过将历史维护次数标准化到机器年龄上，比单纯的维护次数更有信息量\n",
    "# 分母+1是为了避免机器年龄为0时出现除以零的错误\n",
    "df['Maintenance_Frequency'] = df['Maintenance_History_Count'] / (df['Machine_Age'] + 1)\n",
    "print(\"    'Power_Temp_Interaction', 'Vibration_Hours_Interaction', 'Maintenance_Frequency' 已创建。\")\n",
    "\n",
    "\n",
    "# --- 2.4 缺失值与无用字段处理 ---\n",
    "print(\"  [2.4] 正在处理缺失值和删除无用字段...\")\n",
    "# 计算每列的缺失值比例\n",
    "missing_ratio = df.isnull().mean()\n",
    "# 删除缺失比例非常高（例如 > 80%）的列，因为它们信息量太少\n",
    "df.drop(columns=missing_ratio[missing_ratio > 0.8].index, inplace=True)\n",
    "# 删除已经使用完毕的原始特征、ID以及与目标强相关的标签（防止标签泄漏）\n",
    "df.drop(columns=['Machine_ID', 'Remaining_Useful_Life_days', 'Installation_Year', 'Last_Maintenance_Days_Ago'], errors='ignore', inplace=True)\n",
    "\n",
    "# 分离特征矩阵 (X) 和目标向量 (y)\n",
    "y = df['Failure_Within_7_Days']\n",
    "X = df.drop(columns=['Failure_Within_7_Days'])\n",
    "\n",
    "# ===================== 3. 数据划分 =====================\n",
    "print(\"\\n[阶段3] 正在划分训练集与测试集...\")\n",
    "# stratify=y确保在划分后，训练集和测试集中的故障样本比例与原始数据一致，这对于不平衡学习至关重要\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===================== 4. 异常值处理（缩尾法） =====================\n",
    "print(\"\\n[阶段4] 正在处理异常值（缩尾法）...\")\n",
    "# 缩尾法（Winsorizing）是一种处理异常值的方法，它将超出指定分位数范围的极端值替换为该分位数的值\n",
    "def winsorize_dataframes(X_train_df, X_test_df, lower=0.01, upper=0.99):\n",
    "    X_train_processed = X_train_df.copy()\n",
    "    X_test_processed = X_test_df.copy()\n",
    "    # 只对数值型列进行处理\n",
    "    numeric_cols = X_train_processed.select_dtypes(include=np.number).columns\n",
    "    # 遍历所有数值列\n",
    "    for col in numeric_cols:\n",
    "        # 在训练集上学习分位数边界，以防数据泄漏\n",
    "        lower_bound = X_train_processed[col].quantile(lower)\n",
    "        upper_bound = X_train_processed[col].quantile(upper)\n",
    "        # 将学习到的边界同时应用于训练集和测试集\n",
    "        X_train_processed[col] = np.clip(X_train_processed[col], lower_bound, upper_bound)\n",
    "        X_test_processed[col] = np.clip(X_test_processed[col], lower_bound, upper_bound)\n",
    "    return X_train_processed, X_test_processed\n",
    "X_train, X_test = winsorize_dataframes(X_train, X_test)\n",
    "\n",
    "\n",
    "# ===================== 5. 特征编码（独热编码） =====================\n",
    "print(\"\\n[阶段5] 正在进行特征编码...\")\n",
    "# 将类别型特征转换为模型可以理解的数值格式\n",
    "categorical_cols = ['Machine_Type', 'Maintenance_Bin'] \n",
    "# 对训练集进行独热编码\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "# 对测试集进行独热编码\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# 对齐训练集和测试集的列，以处理划分后可能出现的类别不一致问题\n",
    "train_cols = X_train.columns\n",
    "# reindex可以保证测试集的列与训练集完全一致，多出的列用0填充，缺少的列被丢弃\n",
    "X_test = X_test.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "\n",
    "# ===================== 6. 不平衡学习（SMOTETomek） =====================\n",
    "print(\"\\n[阶段6] 正在进行 SMOTETomek 重采样平衡类别...\")\n",
    "# 只保留fit_resample逻辑，不直接对全训练集重采样，留给CV内处理，避免信息泄露\n",
    "# 这里仅初始化SMOTETomek对象，后续CV内使用\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "\n",
    "# ===================== 7. Optuna 超参数调优 =====================\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n[阶段7] 正在使用 Optuna + GPU 进行超参数调优（XGBoost）...\")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 超参数优化目标函数\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 300, 800),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.7, 0.9),\n",
    "        'gamma': trial.suggest_float(\"gamma\", 0, 2),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 1e-2, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 1e-2, 1.0, log=True),\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'predictor': 'gpu_predictor',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        X_tr_res, y_tr_res = smt.fit_resample(X_tr, y_tr)\n",
    "\n",
    "        model.fit(\n",
    "            X_tr_res, y_tr_res,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=30,\n",
    "            verbose=False,\n",
    "            callbacks=[XGBoostPruningCallback(trial, \"validation_0-logloss\")]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_gpu_opt\")\n",
    "study.optimize(objective, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\n[结果] 最佳超参数：\", best_params)\n",
    "\n",
    "\n",
    "# ===================== 8. 训练最终模型 =====================\n",
    "print(\"\\n[阶段8] 正在使用最佳参数训练最终模型...\")\n",
    "\n",
    "# 构造最终模型，增加必要固定参数\n",
    "model = XGBClassifier(\n",
    "    **best_params,\n",
    "    eval_metric='logloss',\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# 对原始训练集做 SMOTETomek 重采样\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_res, y_train_res,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_res,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 封装检测 GPU 使用情况\n",
    "def check_xgb_gpu(model):\n",
    "    try:\n",
    "        booster = model.get_booster()\n",
    "        attrs = booster.attributes()\n",
    "        predictor_used = attrs.get('predictor', 'unknown')\n",
    "        if 'gpu' in predictor_used:\n",
    "            print(f\"✅ 模型正在使用 GPU 预测方式：{predictor_used}\")\n",
    "        else:\n",
    "            print(f\"⚠️ 模型未使用 GPU（实际 predictor: {predictor_used}）\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ 无法确认 GPU 使用状态，请确认模型已训练。\")\n",
    "        print(e)\n",
    "\n",
    "# 验证 GPU 使用状态\n",
    "check_xgb_gpu(model)\n",
    "\n",
    "joblib.dump(model, 'xgboost_fault_prediction_model_v2.pkl')\n",
    "print(\"✅ 模型已保存为 'xgboost_fault_prediction_model_v2.pkl'\")\n",
    "\n",
    "\n",
    "# ===================== 9. 阈值调优与三曲线图 =====================\n",
    "print(\"\\n[阶段9] 正在绘制阈值-指标曲线并选择最佳阈值...\")\n",
    "def plot_threshold_metrics(model, X_val, y_val):\n",
    "    # 获取模型对验证集预测为正类（故障）的概率\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    # 定义一系列要测试的阈值\n",
    "    thresholds = np.linspace(0.1, 0.9, 81)\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    # 遍历所有阈值，计算对应的P, R, F1\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "        # zero_division=0 避免在某些极端阈值下（如所有预测都为负）计算指标时因除以零而报错\n",
    "        precisions.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_val, y_pred, zero_division=0))\n",
    "        f1s.append(f1_score(y_val, y_pred, zero_division=0))\n",
    "\n",
    "    # 寻找一个综合性能较好的阈值，这里使用 F1和Recall之和作为标准\n",
    "    # 在故障预测中，我们通常更关注召回率（不漏报）\n",
    "    best_idx = np.argmax(np.array(f1s) + np.array(recalls))\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, precisions, label='精确率 (Precision)')\n",
    "    plt.plot(thresholds, recalls, label='召回率 (Recall)')\n",
    "    plt.plot(thresholds, f1s, label='F1 分数 (F1-Score)', linewidth=2.5)\n",
    "    # 绘制找到的最佳阈值线\n",
    "    plt.axvline(best_threshold, linestyle='--', color='red', label=f'最优阈值 ≈ {best_threshold:.3f}')\n",
    "    plt.xlabel(\"分类概率阈值\")\n",
    "    plt.ylabel(\"指标值\")\n",
    "    plt.title(\"模型评估指标与分类阈值的关系\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return best_threshold\n",
    "\n",
    "# 在测试集上寻找最佳阈值\n",
    "best_threshold = plot_threshold_metrics(model, X_test, y_test)\n",
    "\n",
    "# ===================== 10. 模型评估 =====================\n",
    "print(f\"\\n[阶段10] 正在使用最优阈值 {best_threshold:.4f} 在测试集上评估模型性能...\")\n",
    "# 获取测试集的预测概率\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "# 使用找到的最佳阈值将概率转换为最终的0/1预测\n",
    "y_pred = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "# 打印各项评估指标\n",
    "print(\"分类报告:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='随机猜测')\n",
    "plt.xlabel(\"假正率 (FPR)\")\n",
    "plt.ylabel(\"真正率 (TPR)\")\n",
    "plt.title(\"ROC 曲线\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===================== 11. 特征重要性分析 =====================\n",
    "print(\"\\n[阶段11] 正在绘制特征重要性图...\")\n",
    "# 从训练好的模型中提取特征重要性\n",
    "# 注意：index必须使用X_train.columns，因为这是经过独热编码后的最终特征名\n",
    "importance = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "# 排序并选出最重要的前5个特征\n",
    "top5 = importance.sort_values(ascending=False).head(5)\n",
    "print(\"\\n前五个重要特征:\\n\", top5)\n",
    "\n",
    "# 绘制条形图\n",
    "plt.figure(figsize=(9, 6))\n",
    "top5.plot(kind='barh', color='teal')\n",
    "plt.title(\"特征重要性 (Top 5)\")\n",
    "plt.xlabel(\"重要性得分 (Importance Score)\")\n",
    "# 将最重要的特征显示在顶部\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===================== 12. 混淆矩阵 =====================\n",
    "print(\"\\n[阶段12] 正在绘制混淆矩阵...\")\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# 使用seaborn的热力图进行可视化\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ===================== 13. SHAP 模型解释 =====================\n",
    "print(\"\\n[阶段13] 正在使用 SHAP 解释模型预测结果...\")\n",
    "# 分析全部测试集数据\n",
    "X_sample = X_test\n",
    "# 对于XGBoost等树模型，使用TreeExplainer效率更高\n",
    "explainer = shap.TreeExplainer(model)\n",
    "# 计算SHAP值\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# SHAP 特征重要性柱状图 (全局解释)\n",
    "print(\"  正在绘制 SHAP 特征重要性柱状图...\")\n",
    "# 该图显示了每个特征对模型输出的平均绝对影响大小\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP 特征重要性 (全局平均影响)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# SHAP 特征影响分布图 (分布解释)\n",
    "print(\"  正在绘制 SHAP 特征影响分布图...\")\n",
    "# 该图不仅显示了特征的重要性，还展示了特征值的变化如何影响预测结果（红色代表高特征值，蓝色代表低特征值）\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.title(\"SHAP 特征重要性与影响分布\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[运行结束] 所有阶段已完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e38a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 确保是原始数据的副本（未采样、未标准化）\n",
    "df_numeric = df.select_dtypes(include=[\"int\", \"float\"]).copy()\n",
    "\n",
    "# ========== Boxplot 异常值可视化 ==========\n",
    "print(\"【1】异常值分布（箱型图）\")\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "df_melted = df_numeric.melt(var_name=\"变量\", value_name=\"值\")\n",
    "sns.boxplot(data=df_melted, x=\"变量\", y=\"值\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"数值型变量异常值分布（箱型图）\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== Z-score 分析高偏离值比例 ==========\n",
    "from scipy.stats import zscore\n",
    "\n",
    "print(\"\\n【2】Z-score 异常值比例（阈值 = ±3）\")\n",
    "z_scores = df_numeric.apply(zscore)\n",
    "outlier_ratio = (np.abs(z_scores) > 3).sum() / df_numeric.shape[0]\n",
    "print(outlier_ratio.sort_values(ascending=False).head(10))\n",
    "\n",
    "# ========== IQR（四分位距）方法文本分析 ==========\n",
    "print(\"\\n【3】IQR 异常值检测结果\")\n",
    "\n",
    "for col in df_numeric.columns:\n",
    "    Q1 = df_numeric[col].quantile(0.25)\n",
    "    Q3 = df_numeric[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outlier_count = ((df_numeric[col] < lower) | (df_numeric[col] > upper)).sum()\n",
    "    outlier_ratio = outlier_count / df_numeric.shape[0]\n",
    "    if outlier_ratio > 0.01:  # 只输出比例大于1%的变量\n",
    "        print(f\"变量【{col}】异常值比例约为 {outlier_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_score, recall_score, f1_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ========== 1. 拟合模型 ==========\n",
    "model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# ========== 2. 预测 ==========\n",
    "y_train_pred = model.predict(X_train_res)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_prob = model.predict_proba(X_train_res)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ========== 3. 输出评估指标 ==========\n",
    "print(\"\\n[训练集评估指标]\")\n",
    "print(classification_report(y_train_res, y_train_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_train_res, y_train_prob))\n",
    "\n",
    "print(\"\\n[测试集评估指标]\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_prob))\n",
    "\n",
    "# ========== 4. 训练集 vs 测试集 指标对比 ==========\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "train_scores = classification_report(y_train_res, y_train_pred, output_dict=True)\n",
    "test_scores = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "print(\"\\n[训练 vs 测试 各项指标差值（测试 - 训练）]:\")\n",
    "for metric in metrics:\n",
    "    delta = test_scores['True'][metric] - train_scores['True'][metric]\n",
    "    print(f\"{metric:<10}: 差值 = {delta:.4f}\")\n",
    "\n",
    "\n",
    "# ========== 5. 混淆矩阵可视化 ==========\n",
    "def plot_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('预测值')\n",
    "    plt.ylabel('实际值')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(y_train_res, y_train_pred, '训练集混淆矩阵')\n",
    "plot_confusion(y_test, y_test_pred, '测试集混淆矩阵')\n",
    "\n",
    "# ========== 6. ROC曲线对比 ==========\n",
    "def plot_roc_curve(fpr1, tpr1, auc1, fpr2, tpr2, auc2):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr1, tpr1, label=f'训练集 (AUC = {auc1:.4f})')\n",
    "    plt.plot(fpr2, tpr2, label=f'测试集 (AUC = {auc2:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('假阳性率 (FPR)')\n",
    "    plt.ylabel('真正率 (TPR)')\n",
    "    plt.title('ROC 曲线对比')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_res, y_train_prob)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "auc_train = roc_auc_score(y_train_res, y_train_prob)\n",
    "auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "plot_roc_curve(fpr_train, tpr_train, auc_train, fpr_test, tpr_test, auc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_scores.keys())\n",
    "print(test_scores.keys())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2025-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
