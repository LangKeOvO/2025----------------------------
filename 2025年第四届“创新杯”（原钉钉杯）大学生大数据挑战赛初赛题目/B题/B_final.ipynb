{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"111111111111111111111111111111111111111111111111111111111111111111111\")\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "TARGET = \"Remaining_Useful_Life_days\"\n",
    "base_features = [\n",
    "    'Operational_Hours', 'Temperature_C', 'Vibration_mms',\n",
    "    'Oil_Level_pct', 'Coolant_Level_pct',\n",
    "    'Maintenance_History_Count', 'Failure_History_Count'\n",
    "]\n",
    "optional_features = [\n",
    "    'Sound_dB', 'Power_Consumption_kW',\n",
    "    'Last_Maintenance_Days_Ago', 'Machine_Type',\n",
    "    'AI_Supervision', 'Installation_Year'\n",
    "]\n",
    "all_features = [c for c in base_features + optional_features if c in df.columns]\n",
    "df = df[df[TARGET].notna()].copy()\n",
    "for c in ['Machine_Type', 'AI_Supervision']:\n",
    "    if c in all_features:\n",
    "        df[c] = LabelEncoder().fit_transform(df[c].astype(str))\n",
    "if 'Operational_Hours' in df and 'Maintenance_History_Count' in df:\n",
    "    df['Hours_per_Maintenance'] = df['Operational_Hours'] / (df['Maintenance_History_Count'] + 1)\n",
    "    all_features.append('Hours_per_Maintenance')\n",
    "if 'Failure_History_Count' in df and 'Operational_Hours' in df:\n",
    "    df['Failure_Rate'] = df['Failure_History_Count'] / (df['Operational_Hours'] + 1)\n",
    "    all_features.append('Failure_Rate')\n",
    "for c in ['Temperature_C', 'Vibration_mms', 'Sound_dB']:\n",
    "    if c in all_features:\n",
    "        lo, hi = df[c].quantile(0.01), df[c].quantile(0.99)\n",
    "        df[c] = df[c].clip(lo, hi)\n",
    "X = df[all_features]\n",
    "y = df[TARGET].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集：{X_train.shape}, 测试集：{X_test.shape}, 特征数：{len(all_features)}\")\n",
    "def evaluate(name, model, X_tr, X_te, y_tr, y_te, cv=True):\n",
    "    st = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_te)\n",
    "    mse = mean_squared_error(y_te, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_te, pred)\n",
    "\n",
    "    cv_r2 = None\n",
    "    if cv:\n",
    "        kf = KFold(5, shuffle=True, random_state=42)\n",
    "        cv_r2 = cross_val_score(model, X_tr, y_tr, cv=kf, scoring='r2', n_jobs=8).mean()\n",
    "\n",
    "    print(f\"[{name}]  MSE={mse:.1f}  RMSE={rmse:.3f}  R2={r2:.4f}\"\n",
    "          + (f\"  (CV_R2={cv_r2:.4f})\" if cv_r2 is not None else \"\")\n",
    "          + f\"  [{time.time()-st:.1f}s]\")\n",
    "    return {\"model\": name, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2, \"CV_R2\": cv_r2}\n",
    "\n",
    "results = []\n",
    "lin = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "results.append(evaluate(\"Linear\", lin, X_train, X_test, y_train, y_test))\n",
    "\n",
    "ridge = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"rg\", RidgeCV(alphas=[0.1, 1, 10]))\n",
    "])\n",
    "results.append(evaluate(\"RidgeCV\", ridge, X_train, X_test, y_train, y_test))\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200, max_depth=12, random_state=42, n_jobs=8\n",
    ")\n",
    "results.append(evaluate(\"RandomForest\", rf, X_train, X_test, y_train, y_test))\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=6,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    tree_method=\"hist\", n_jobs=8, random_state=42\n",
    ")\n",
    "results.append(evaluate(\"XGB\", xgb, X_train, X_test, y_train, y_test))\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=200, learning_rate=0.05,\n",
    "    num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n",
    "    n_jobs=8, random_state=42, verbose=-1\n",
    ")\n",
    "results.append(evaluate(\"LightGBM\", lgbm, X_train, X_test, y_train, y_test))\n",
    "cat = CatBoostRegressor(\n",
    "    iterations=400, learning_rate=0.05, depth=6,\n",
    "    verbose=False, thread_count=8, random_seed=42\n",
    ")\n",
    "results.append(evaluate(\"CatBoost\", cat, X_train, X_test, y_train, y_test))\n",
    "base_models = [\n",
    "    ('rf', rf),\n",
    "    ('xgb', xgb),\n",
    "    ('lgbm', lgbm),\n",
    "    ('cat', cat),\n",
    "]\n",
    "meta = RidgeCV(alphas=[0.1, 1, 10])\n",
    "stack = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta,\n",
    "    cv=5,\n",
    "    passthrough=True,\n",
    "    n_jobs=8\n",
    ")\n",
    "results.append(evaluate(\"Stacking\", stack, X_train, X_test, y_train, y_test))\n",
    "df_res = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "print(\"\\n====== 最终结果 排名======\")\n",
    "print(df_res.to_string(index=False))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "y_pred = stack.predict(X_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# 1. 预测值 vs 实际值\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"实际值\")\n",
    "plt.ylabel(\"预测值\")\n",
    "plt.title(\"预测值 vs 实际值\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 残差图\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.3)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"预测值\")\n",
    "plt.ylabel(\"残差\")\n",
    "plt.title(\"残差图\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 残差分布\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"残差分布直方图\")\n",
    "plt.xlabel(\"残差\")\n",
    "plt.ylabel(\"频数\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. 特征重要性图（以XGB为例）\n",
    "importances = xgb.feature_importances_\n",
    "feat_names = X_train.columns\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(range(len(sorted_idx[:15])), importances[sorted_idx[:15]][::-1])\n",
    "plt.yticks(range(len(sorted_idx[:15])), feat_names[sorted_idx[:15]][::-1])\n",
    "plt.xlabel(\"重要性\")\n",
    "plt.title(\"XGBoost特征重要性\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2025-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
